{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3755fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c1f520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img_type, input_image):\n",
    "    if img_type == \"vit\":\n",
    "        config = resolve_data_config({}, model=vit_model, verbose=1)\n",
    "        transform = create_transform(**config)\n",
    "        with torch.no_grad():\n",
    "            img = Image.open(input_image).convert(\"RGB\")\n",
    "            input = transform(img).unsqueeze(0)\n",
    "            feature = vit_model.forward_features(input)\n",
    "        return feature\n",
    "    \n",
    "    elif img_type == \"detr\":\n",
    "        transform = T.Compose([\n",
    "            T.Resize(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        with torch.no_grad():\n",
    "            img = Image.open(input_image).convert(\"RGB\")\n",
    "            input = transform(img).unsqueeze(0)\n",
    "            feature = detr_model(input)[-1]\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97d1f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '100',\n",
       " '10001',\n",
       " '10003',\n",
       " '10007',\n",
       " '10008',\n",
       " '10009',\n",
       " '1001',\n",
       " '10010',\n",
       " '10014',\n",
       " '10015',\n",
       " '10017',\n",
       " '10019',\n",
       " '1002',\n",
       " '10023',\n",
       " '10024',\n",
       " '10025',\n",
       " '10026',\n",
       " '10027',\n",
       " '1003',\n",
       " '10032',\n",
       " '10038',\n",
       " '10039',\n",
       " '10044',\n",
       " '10046',\n",
       " '10053',\n",
       " '10055',\n",
       " '10056',\n",
       " '10057',\n",
       " '10059',\n",
       " '10066',\n",
       " '10067',\n",
       " '10069',\n",
       " '10071',\n",
       " '10072',\n",
       " '10073',\n",
       " '10076',\n",
       " '10077',\n",
       " '10078',\n",
       " '10079',\n",
       " '10080',\n",
       " '10081',\n",
       " '10082',\n",
       " '10084',\n",
       " '10085',\n",
       " '10087',\n",
       " '10088',\n",
       " '1009',\n",
       " '10090',\n",
       " '10092',\n",
       " '10094',\n",
       " '10095',\n",
       " '10098',\n",
       " '10099',\n",
       " '101',\n",
       " '1010',\n",
       " '10100',\n",
       " '10105',\n",
       " '10107',\n",
       " '1011',\n",
       " '10111',\n",
       " '10116',\n",
       " '10117',\n",
       " '10118',\n",
       " '1012',\n",
       " '10123',\n",
       " '10126',\n",
       " '10128',\n",
       " '1013',\n",
       " '10130',\n",
       " '10132',\n",
       " '10134',\n",
       " '10135',\n",
       " '10139',\n",
       " '1014',\n",
       " '10141',\n",
       " '10143',\n",
       " '10145',\n",
       " '10147',\n",
       " '10148',\n",
       " '1015',\n",
       " '10150',\n",
       " '10152',\n",
       " '10157',\n",
       " '10159',\n",
       " '10161',\n",
       " '10162',\n",
       " '10163',\n",
       " '10168',\n",
       " '10169',\n",
       " '1017',\n",
       " '10171',\n",
       " '10172',\n",
       " '10176',\n",
       " '10177',\n",
       " '10178',\n",
       " '10179',\n",
       " '1018',\n",
       " '10180',\n",
       " '10181',\n",
       " '10182',\n",
       " '10183',\n",
       " '10184',\n",
       " '10185',\n",
       " '10186',\n",
       " '10188',\n",
       " '10194',\n",
       " '10197',\n",
       " '10198',\n",
       " '10202',\n",
       " '10204',\n",
       " '10205',\n",
       " '10207',\n",
       " '10208',\n",
       " '10209',\n",
       " '1021',\n",
       " '10211',\n",
       " '10212',\n",
       " '10213',\n",
       " '10215',\n",
       " '10216',\n",
       " '1022',\n",
       " '10222',\n",
       " '10223',\n",
       " '10224',\n",
       " '10226',\n",
       " '10229',\n",
       " '1023',\n",
       " '10230',\n",
       " '10231',\n",
       " '10233',\n",
       " '10234',\n",
       " '10237',\n",
       " '10239',\n",
       " '1024',\n",
       " '10240',\n",
       " '10241',\n",
       " '10242',\n",
       " '10243',\n",
       " '10244',\n",
       " '10246',\n",
       " '10247',\n",
       " '10248',\n",
       " '10250',\n",
       " '10253',\n",
       " '10254',\n",
       " '10255',\n",
       " '10256',\n",
       " '10258',\n",
       " '1026',\n",
       " '10260',\n",
       " '10261',\n",
       " '10262',\n",
       " '10263',\n",
       " '10266',\n",
       " '10269',\n",
       " '1027',\n",
       " '10270',\n",
       " '10271',\n",
       " '10274',\n",
       " '10278',\n",
       " '10279',\n",
       " '10283',\n",
       " '10284',\n",
       " '10286',\n",
       " '10288',\n",
       " '1029',\n",
       " '10290',\n",
       " '10293',\n",
       " '10295',\n",
       " '10296',\n",
       " '10297',\n",
       " '1030',\n",
       " '10301',\n",
       " '10302',\n",
       " '10307',\n",
       " '10309',\n",
       " '10310',\n",
       " '10311',\n",
       " '10312',\n",
       " '10313',\n",
       " '10315',\n",
       " '10316',\n",
       " '10317',\n",
       " '10319',\n",
       " '1032',\n",
       " '10321',\n",
       " '10323',\n",
       " '10324',\n",
       " '10326',\n",
       " '10327',\n",
       " '10328',\n",
       " '10329',\n",
       " '1033',\n",
       " '10330',\n",
       " '10331',\n",
       " '10333',\n",
       " '10335',\n",
       " '10337',\n",
       " '10338',\n",
       " '10339',\n",
       " '1034',\n",
       " '10341',\n",
       " '10343',\n",
       " '10344',\n",
       " '1035',\n",
       " '10350',\n",
       " '10355',\n",
       " '10356',\n",
       " '10358',\n",
       " '1036',\n",
       " '10360',\n",
       " '10363',\n",
       " '10364',\n",
       " '10366',\n",
       " '10368',\n",
       " '10369',\n",
       " '10372',\n",
       " '10373',\n",
       " '10374',\n",
       " '10376',\n",
       " '10377',\n",
       " '10378',\n",
       " '10379',\n",
       " '1038',\n",
       " '10381',\n",
       " '10382',\n",
       " '10383',\n",
       " '10386',\n",
       " '1039',\n",
       " '10391',\n",
       " '10393',\n",
       " '10394',\n",
       " '10395',\n",
       " '10398',\n",
       " '10399',\n",
       " '1040',\n",
       " '10401',\n",
       " '10402',\n",
       " '10404',\n",
       " '10405',\n",
       " '10407',\n",
       " '10408',\n",
       " '1041',\n",
       " '10411',\n",
       " '10413',\n",
       " '10414',\n",
       " '10418',\n",
       " '1042',\n",
       " '10422',\n",
       " '10423',\n",
       " '10425',\n",
       " '10426',\n",
       " '10429',\n",
       " '1043',\n",
       " '10430',\n",
       " '10433',\n",
       " '10434',\n",
       " '10440',\n",
       " '10441',\n",
       " '10444',\n",
       " '10448',\n",
       " '10449',\n",
       " '10452',\n",
       " '10454',\n",
       " '10455',\n",
       " '10456',\n",
       " '10458',\n",
       " '10459',\n",
       " '10461',\n",
       " '10463',\n",
       " '10465',\n",
       " '10466',\n",
       " '10468',\n",
       " '10469',\n",
       " '10472',\n",
       " '10473',\n",
       " '10477',\n",
       " '10479',\n",
       " '1048',\n",
       " '10483',\n",
       " '10484',\n",
       " '10485',\n",
       " '10488',\n",
       " '1049',\n",
       " '10490',\n",
       " '10494',\n",
       " '10495',\n",
       " '10496',\n",
       " '10497',\n",
       " '10498',\n",
       " '105',\n",
       " '1050',\n",
       " '10500',\n",
       " '10502',\n",
       " '10503',\n",
       " '10505',\n",
       " '10506',\n",
       " '10507',\n",
       " '10509',\n",
       " '10511',\n",
       " '10512',\n",
       " '10513',\n",
       " '10515',\n",
       " '10516',\n",
       " '10517',\n",
       " '10518',\n",
       " '10519',\n",
       " '1052',\n",
       " '10520',\n",
       " '10521',\n",
       " '10522',\n",
       " '10523',\n",
       " '10525',\n",
       " '10527',\n",
       " '10531',\n",
       " '10532',\n",
       " '10536',\n",
       " '10541',\n",
       " '10544',\n",
       " '10545',\n",
       " '10546',\n",
       " '1055',\n",
       " '10550',\n",
       " '10551',\n",
       " '10553',\n",
       " '10554',\n",
       " '10555',\n",
       " '10556',\n",
       " '10558',\n",
       " '10559',\n",
       " '10560',\n",
       " '10561',\n",
       " '10562',\n",
       " '10563',\n",
       " '10566',\n",
       " '10567',\n",
       " '10569',\n",
       " '1057',\n",
       " '10571',\n",
       " '10573',\n",
       " '10574',\n",
       " '10576',\n",
       " '1058',\n",
       " '10581',\n",
       " '10582',\n",
       " '10584',\n",
       " '10585',\n",
       " '10586',\n",
       " '10588',\n",
       " '10589',\n",
       " '10590',\n",
       " '10592',\n",
       " '10593',\n",
       " '10594',\n",
       " '10595',\n",
       " '10596',\n",
       " '10598',\n",
       " '10599',\n",
       " '106',\n",
       " '1060',\n",
       " '10603',\n",
       " '10605',\n",
       " '10606',\n",
       " '10611',\n",
       " '10612',\n",
       " '10614',\n",
       " '10615',\n",
       " '10616',\n",
       " '10617',\n",
       " '10618',\n",
       " '10619',\n",
       " '1062',\n",
       " '10620',\n",
       " '10622',\n",
       " '10624',\n",
       " '10625',\n",
       " '10628',\n",
       " '10629',\n",
       " '10632',\n",
       " '10633',\n",
       " '10636',\n",
       " '10638',\n",
       " '1064',\n",
       " '10644',\n",
       " '10645',\n",
       " '10649',\n",
       " '10650',\n",
       " '10651',\n",
       " '10659',\n",
       " '1066',\n",
       " '10661',\n",
       " '10662',\n",
       " '10665',\n",
       " '10669',\n",
       " '1067',\n",
       " '10671',\n",
       " '10674',\n",
       " '10677',\n",
       " '10679',\n",
       " '1068',\n",
       " '10680',\n",
       " '10681',\n",
       " '10682',\n",
       " '10683',\n",
       " '10684',\n",
       " '10685',\n",
       " '10687',\n",
       " '10688',\n",
       " '10689',\n",
       " '10691',\n",
       " '10692',\n",
       " '10693',\n",
       " '10695',\n",
       " '10698',\n",
       " '10699',\n",
       " '107',\n",
       " '1070',\n",
       " '10700',\n",
       " '10701',\n",
       " '10704',\n",
       " '10706',\n",
       " '10707',\n",
       " '10708',\n",
       " '10709',\n",
       " '1071',\n",
       " '10715',\n",
       " '10717',\n",
       " '10718',\n",
       " '1072',\n",
       " '10720',\n",
       " '10721',\n",
       " '10722',\n",
       " '10724',\n",
       " '10725',\n",
       " '10727',\n",
       " '10728',\n",
       " '10729',\n",
       " '10730',\n",
       " '10732',\n",
       " '10733',\n",
       " '10734',\n",
       " '10735',\n",
       " '10737',\n",
       " '10738',\n",
       " '10739',\n",
       " '1074',\n",
       " '10740',\n",
       " '10741',\n",
       " '10742',\n",
       " '10745',\n",
       " '10747',\n",
       " '1075',\n",
       " '10750',\n",
       " '10752',\n",
       " '10760',\n",
       " '10761',\n",
       " '10762',\n",
       " '10763',\n",
       " '10767',\n",
       " '10768',\n",
       " '1077',\n",
       " '10774',\n",
       " '10775',\n",
       " '10776',\n",
       " '10777',\n",
       " '10778',\n",
       " '10779',\n",
       " '1078',\n",
       " '10780',\n",
       " '10782',\n",
       " '10787',\n",
       " '10791',\n",
       " '10792',\n",
       " '10793',\n",
       " '10794',\n",
       " '10799',\n",
       " '10803',\n",
       " '10805',\n",
       " '10806',\n",
       " '10807',\n",
       " '10809',\n",
       " '10811',\n",
       " '10813',\n",
       " '10814',\n",
       " '10817',\n",
       " '10821',\n",
       " '10822',\n",
       " '10824',\n",
       " '10826',\n",
       " '10829',\n",
       " '10830',\n",
       " '10833',\n",
       " '10834',\n",
       " '10835',\n",
       " '10836',\n",
       " '10839',\n",
       " '1084',\n",
       " '10840',\n",
       " '10843',\n",
       " '10845',\n",
       " '10848',\n",
       " '1085',\n",
       " '10850',\n",
       " '10851',\n",
       " '10856',\n",
       " '10859',\n",
       " '10861',\n",
       " '10862',\n",
       " '10863',\n",
       " '10866',\n",
       " '10867',\n",
       " '10868',\n",
       " '10870',\n",
       " '10871',\n",
       " '10872',\n",
       " '10873',\n",
       " '10875',\n",
       " '10878',\n",
       " '10879',\n",
       " '10881',\n",
       " '10883',\n",
       " '10886',\n",
       " '10887',\n",
       " '10888',\n",
       " '10889',\n",
       " '10891',\n",
       " '10892',\n",
       " '10893',\n",
       " '10894',\n",
       " '10897',\n",
       " '10899',\n",
       " '10900',\n",
       " '10901',\n",
       " '10903',\n",
       " '10904',\n",
       " '10905',\n",
       " '10909',\n",
       " '1091',\n",
       " '10910',\n",
       " '10911',\n",
       " '10912',\n",
       " '10916',\n",
       " '10917',\n",
       " '10918',\n",
       " '10919',\n",
       " '1092',\n",
       " '10925',\n",
       " '10928',\n",
       " '10929',\n",
       " '10930',\n",
       " '10933',\n",
       " '10936',\n",
       " '10938',\n",
       " '10941',\n",
       " '10943',\n",
       " '10944',\n",
       " '10945',\n",
       " '10946',\n",
       " '10947',\n",
       " '10949',\n",
       " '10952',\n",
       " '10953',\n",
       " '10955',\n",
       " '10956',\n",
       " '10958',\n",
       " '10959',\n",
       " '10960',\n",
       " '10962',\n",
       " '10963',\n",
       " '10964',\n",
       " '10968',\n",
       " '10971',\n",
       " '10972',\n",
       " '10973',\n",
       " '10975',\n",
       " '10977',\n",
       " '10978',\n",
       " '10984',\n",
       " '10986',\n",
       " '10990',\n",
       " '10993',\n",
       " '10994',\n",
       " '10997',\n",
       " '10998',\n",
       " '11',\n",
       " '1100',\n",
       " '11001',\n",
       " '11008',\n",
       " '11009',\n",
       " '1101',\n",
       " '11012',\n",
       " '11013',\n",
       " '11014',\n",
       " '11015',\n",
       " '11016',\n",
       " '1102',\n",
       " '11021',\n",
       " '11022',\n",
       " '11023',\n",
       " '11024',\n",
       " '11025',\n",
       " '11026',\n",
       " '11028',\n",
       " '11029',\n",
       " '11030',\n",
       " '11031',\n",
       " '11032',\n",
       " '11033',\n",
       " '11034',\n",
       " '11035',\n",
       " '11037',\n",
       " '11038',\n",
       " '11040',\n",
       " '11041',\n",
       " '11042',\n",
       " '11045',\n",
       " '11047',\n",
       " '11052',\n",
       " '11054',\n",
       " '11057',\n",
       " '11060',\n",
       " '11061',\n",
       " '11066',\n",
       " '11067',\n",
       " '1107',\n",
       " '11070',\n",
       " '11073',\n",
       " '11074',\n",
       " '11075',\n",
       " '11076',\n",
       " '11078',\n",
       " '1108',\n",
       " '11080',\n",
       " '11082',\n",
       " '11083',\n",
       " '11084',\n",
       " '11087',\n",
       " '11088',\n",
       " '11089',\n",
       " '1109',\n",
       " '11091',\n",
       " '11092',\n",
       " '11093',\n",
       " '11095',\n",
       " '11097',\n",
       " '11098',\n",
       " '111',\n",
       " '11100',\n",
       " '11101',\n",
       " '11103',\n",
       " '11104',\n",
       " '11107',\n",
       " '11110',\n",
       " '11111',\n",
       " '11113',\n",
       " '11115',\n",
       " '11116',\n",
       " '11117',\n",
       " '1112',\n",
       " '11120',\n",
       " '11123',\n",
       " '11124',\n",
       " '11128',\n",
       " '11129',\n",
       " '11133',\n",
       " '11134',\n",
       " '11136',\n",
       " '11138',\n",
       " '11139',\n",
       " '11141',\n",
       " '11144',\n",
       " '11145',\n",
       " '11146',\n",
       " '11147',\n",
       " '11148',\n",
       " '11149',\n",
       " '1115',\n",
       " '11153',\n",
       " '11155',\n",
       " '11156',\n",
       " '11159',\n",
       " '11160',\n",
       " '11161',\n",
       " '11166',\n",
       " '11167',\n",
       " '1117',\n",
       " '11170',\n",
       " '11171',\n",
       " '11172',\n",
       " '11174',\n",
       " '11175',\n",
       " '11176',\n",
       " '11177',\n",
       " '11178',\n",
       " '11180',\n",
       " '11181',\n",
       " '11183',\n",
       " '11188',\n",
       " '11189',\n",
       " '1119',\n",
       " '11190',\n",
       " '11196',\n",
       " '11197',\n",
       " '11199',\n",
       " '112',\n",
       " '11200',\n",
       " '11201',\n",
       " '11204',\n",
       " '11207',\n",
       " '11208',\n",
       " '1121',\n",
       " '11212',\n",
       " '11213',\n",
       " '11214',\n",
       " '11217',\n",
       " '1122',\n",
       " '11225',\n",
       " '11226',\n",
       " '11227',\n",
       " '1123',\n",
       " '11230',\n",
       " '11232',\n",
       " '11236',\n",
       " '11237',\n",
       " '11239',\n",
       " '1124',\n",
       " '11240',\n",
       " '11241',\n",
       " '11243',\n",
       " '11245',\n",
       " '11246',\n",
       " '1125',\n",
       " '11251',\n",
       " '11252',\n",
       " '11253',\n",
       " '11254',\n",
       " '11256',\n",
       " '11258',\n",
       " '1126',\n",
       " '11260',\n",
       " '11265',\n",
       " '11268',\n",
       " '1127',\n",
       " '11271',\n",
       " '11273',\n",
       " '11274',\n",
       " '11277',\n",
       " '11278',\n",
       " '1128',\n",
       " '11283',\n",
       " '11284',\n",
       " '11285',\n",
       " '11286',\n",
       " '11287',\n",
       " '11288',\n",
       " '11291',\n",
       " '11293',\n",
       " '11294',\n",
       " '11295',\n",
       " '11296',\n",
       " '11297',\n",
       " '11299',\n",
       " '1130',\n",
       " '11300',\n",
       " '11301',\n",
       " '11302',\n",
       " '11303',\n",
       " '11305',\n",
       " '11307',\n",
       " '11308',\n",
       " '11311',\n",
       " '11313',\n",
       " '11314',\n",
       " '11315',\n",
       " '11320',\n",
       " '11321',\n",
       " '11323',\n",
       " '11327',\n",
       " '11329',\n",
       " '1133',\n",
       " '11330',\n",
       " '11333',\n",
       " '11334',\n",
       " '11336',\n",
       " '11337',\n",
       " '11338',\n",
       " '11339',\n",
       " '11342',\n",
       " '11344',\n",
       " '11348',\n",
       " '11349',\n",
       " '1135',\n",
       " '11352',\n",
       " '11353',\n",
       " '11356',\n",
       " '11357',\n",
       " '11358',\n",
       " '11359',\n",
       " '1136',\n",
       " '11363',\n",
       " '11364',\n",
       " '11372',\n",
       " '11373',\n",
       " '11374',\n",
       " '11375',\n",
       " '11376',\n",
       " '11377',\n",
       " '1138',\n",
       " '11382',\n",
       " '11384',\n",
       " '11385',\n",
       " '11387',\n",
       " '1139',\n",
       " '11391',\n",
       " '11398',\n",
       " '11399',\n",
       " '1140',\n",
       " '11401',\n",
       " '11402',\n",
       " '11403',\n",
       " '11405',\n",
       " '11406',\n",
       " '11407',\n",
       " '11408',\n",
       " '11409',\n",
       " '11411',\n",
       " '11413',\n",
       " '11414',\n",
       " '11415',\n",
       " '11419',\n",
       " '11421',\n",
       " '11423',\n",
       " '11428',\n",
       " '11429',\n",
       " '1143',\n",
       " '11431',\n",
       " '11432',\n",
       " '11433',\n",
       " '11434',\n",
       " '11435',\n",
       " '11437',\n",
       " '11438',\n",
       " '11440',\n",
       " '11441',\n",
       " '11442',\n",
       " '11443',\n",
       " '11446',\n",
       " '11447',\n",
       " '11448',\n",
       " '1145',\n",
       " '11451',\n",
       " '11452',\n",
       " '11453',\n",
       " '11456',\n",
       " '11458',\n",
       " '11459',\n",
       " '11460',\n",
       " '11461',\n",
       " '11462',\n",
       " '11463',\n",
       " '11466',\n",
       " '11468',\n",
       " '11470',\n",
       " '11473',\n",
       " '11474',\n",
       " '11478',\n",
       " '11479',\n",
       " '1148',\n",
       " '11482',\n",
       " '11484',\n",
       " '11486',\n",
       " '11488',\n",
       " '1149',\n",
       " '11490',\n",
       " '11491',\n",
       " '11493',\n",
       " '11499',\n",
       " '1150',\n",
       " '11502',\n",
       " '11506',\n",
       " '11507',\n",
       " '11508',\n",
       " '11509',\n",
       " '11512',\n",
       " '11514',\n",
       " '11516',\n",
       " '11517',\n",
       " '1152',\n",
       " '11520',\n",
       " '11521',\n",
       " '11523',\n",
       " '11524',\n",
       " '11525',\n",
       " '11527',\n",
       " '11529',\n",
       " '11530',\n",
       " '11532',\n",
       " '11533',\n",
       " '11535',\n",
       " '11536',\n",
       " '11537',\n",
       " '11538',\n",
       " '11539',\n",
       " '11541',\n",
       " '11546',\n",
       " '11547',\n",
       " '11550',\n",
       " '11551',\n",
       " '11552',\n",
       " '11554',\n",
       " '11558',\n",
       " '11559',\n",
       " '1156',\n",
       " '11561',\n",
       " '11564',\n",
       " '11566',\n",
       " '11568',\n",
       " '11569',\n",
       " '11570',\n",
       " '11572',\n",
       " '11573',\n",
       " '11574',\n",
       " '11577',\n",
       " '11578',\n",
       " '11579',\n",
       " '1158',\n",
       " '11580',\n",
       " '11583',\n",
       " '11585',\n",
       " '11587',\n",
       " '1159',\n",
       " '11590',\n",
       " '11592',\n",
       " '11593',\n",
       " '11595',\n",
       " '11596',\n",
       " '11599',\n",
       " '116',\n",
       " '11600',\n",
       " '11605',\n",
       " '11606',\n",
       " '11607',\n",
       " '11608',\n",
       " '11609',\n",
       " '11610',\n",
       " '11613',\n",
       " '11614',\n",
       " '11615',\n",
       " '11616',\n",
       " '11618',\n",
       " '11619',\n",
       " '1162',\n",
       " '11620',\n",
       " '11622',\n",
       " '11623',\n",
       " '11624',\n",
       " '11625',\n",
       " '11626',\n",
       " '11627',\n",
       " '11628',\n",
       " '11630',\n",
       " '11631',\n",
       " '11634',\n",
       " '11636',\n",
       " '11637',\n",
       " '11638',\n",
       " '11642',\n",
       " '11643',\n",
       " '11644',\n",
       " '11645',\n",
       " '11646',\n",
       " '11649',\n",
       " '1165',\n",
       " '11650',\n",
       " '11651',\n",
       " '11653',\n",
       " '11655',\n",
       " '11656',\n",
       " '11657',\n",
       " '11660',\n",
       " '11661',\n",
       " '11664',\n",
       " '11666',\n",
       " '11668',\n",
       " '11669',\n",
       " '11673',\n",
       " '11675',\n",
       " '1168',\n",
       " '11681',\n",
       " '11682',\n",
       " '11684',\n",
       " '11685',\n",
       " '11690',\n",
       " '11695',\n",
       " '11696',\n",
       " '11697',\n",
       " '11699',\n",
       " '11700',\n",
       " '11702',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root = 'data/images'\n",
    "all_images = os.listdir(data_root)\n",
    "all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7314eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11208\n"
     ]
    }
   ],
   "source": [
    "tmp = []\n",
    "name_map = {}\n",
    "all_images.sort(key=lambda x:int(x))\n",
    "print(len(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3196d512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 1024, kernel_size=(32, 32), stride=(32, 32))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (patch_drop): Identity()\n",
       "  (norm_pre): Identity()\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (12): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (13): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (14): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (15): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (16): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (17): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (18): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (19): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (20): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (21): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (22): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (23): Block(\n",
       "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "  (fc_norm): Identity()\n",
       "  (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  (head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_model = timm.create_model(\"vit_large_patch32_384\", pretrained=True, num_classes=0)\n",
    "vit_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0b3efb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                        | 0/11208 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                           | 100/11208 [01:23<2:48:37,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▎                                                                          | 200/11208 [02:38<2:16:04,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██                                                                          | 300/11208 [03:53<2:07:31,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▋                                                                         | 400/11208 [05:13<2:14:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▍                                                                        | 500/11208 [06:35<2:50:15,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████                                                                        | 600/11208 [08:08<2:22:19,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▋                                                                       | 699/11208 [09:37<2:43:56,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▍                                                                      | 800/11208 [11:05<2:19:20,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████                                                                      | 900/11208 [12:34<2:19:19,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████▋                                                                    | 1000/11208 [14:02<2:35:06,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▎                                                                   | 1100/11208 [15:32<2:02:54,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████                                                                   | 1200/11208 [16:58<2:09:09,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████▋                                                                  | 1300/11208 [18:26<1:44:44,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▎                                                                 | 1400/11208 [19:56<2:47:13,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████                                                                 | 1499/11208 [21:28<2:50:48,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████▋                                                                | 1600/11208 [22:59<2:30:17,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▍                                                               | 1700/11208 [24:30<2:29:08,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████                                                               | 1800/11208 [25:57<2:18:16,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████▋                                                              | 1900/11208 [27:29<2:17:44,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████▍                                                             | 2000/11208 [29:02<2:00:15,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████                                                             | 2100/11208 [30:35<2:33:27,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████▋                                                            | 2200/11208 [32:04<1:56:38,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████▍                                                           | 2300/11208 [33:34<2:07:39,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████                                                           | 2400/11208 [35:10<1:47:42,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████▋                                                          | 2500/11208 [36:50<2:46:25,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████▍                                                         | 2600/11208 [38:19<2:27:50,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████                                                         | 2700/11208 [39:52<1:36:38,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████▋                                                        | 2800/11208 [41:22<2:18:03,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████▍                                                       | 2900/11208 [42:52<1:48:19,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████                                                       | 3000/11208 [44:25<2:07:12,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████▋                                                      | 3100/11208 [45:57<1:57:39,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████▍                                                     | 3200/11208 [47:26<1:51:51,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████                                                     | 3300/11208 [48:54<1:43:34,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▊                                                    | 3400/11208 [50:29<2:20:38,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████▍                                                   | 3500/11208 [52:05<2:00:53,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████                                                   | 3600/11208 [53:38<1:45:15,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████▊                                                  | 3700/11208 [55:09<2:00:34,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████▍                                                 | 3800/11208 [56:39<1:59:01,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████                                                 | 3899/11208 [58:20<1:57:56,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████▊                                                | 3999/11208 [59:58<1:26:07,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████▋                                              | 4100/11208 [1:01:36<2:14:05,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████▎                                             | 4200/11208 [1:03:09<1:41:14,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████                                             | 4300/11208 [1:04:45<1:45:10,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████████████████▋                                            | 4400/11208 [1:06:29<1:18:50,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████▎                                           | 4500/11208 [1:08:01<1:43:46,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████████████████▉                                           | 4600/11208 [1:09:38<1:48:17,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████▌                                          | 4700/11208 [1:11:07<1:45:27,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████████████████████████████▎                                         | 4800/11208 [1:12:42<1:37:27,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████▉                                         | 4900/11208 [1:14:20<1:46:39,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████████████████████▌                                        | 5000/11208 [1:15:53<1:36:24,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████▏                                       | 5100/11208 [1:17:27<1:38:01,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████▊                                       | 5200/11208 [1:19:04<1:45:43,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████████████████████▌                                      | 5300/11208 [1:20:36<1:50:57,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████████████████████▏                                     | 5400/11208 [1:22:06<1:28:43,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████▊                                     | 5500/11208 [1:23:38<1:33:21,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████▍                                    | 5600/11208 [1:25:10<1:27:01,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████████████████████████▏                                   | 5700/11208 [1:26:35<1:11:09,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████▏                                 | 5798/11208 [2:47:52<519:54:45, 345.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████████████████████▍                                  | 5900/11208 [2:49:19<1:02:40,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████████████                                  | 6000/11208 [2:50:37<1:10:41,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████████████▋                                 | 6100/11208 [2:52:10<1:29:24,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████████████████████▍                                | 6200/11208 [2:53:47<1:22:32,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████████████                                | 6300/11208 [2:55:18<1:17:40,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████▋                               | 6400/11208 [2:56:50<1:23:17,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████████████▎                              | 6500/11208 [2:58:28<1:12:54,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████████████████████████████▉                              | 6600/11208 [2:59:50<1:01:14,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████▋                             | 6700/11208 [3:01:19<1:10:08,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████████████▎                            | 6800/11208 [3:02:42<1:02:48,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████████████████████████▉                            | 6900/11208 [3:04:11<1:01:52,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████▊                            | 7000/11208 [3:05:34<52:25,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████████▌                           | 7100/11208 [3:06:59<53:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████████████████████████▏                          | 7200/11208 [3:08:28<56:19,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████▊                          | 7300/11208 [3:09:56<58:01,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████▏                        | 7400/11208 [3:11:22<1:02:25,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████▏                        | 7500/11208 [3:12:54<48:42,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████████████████████████████▍                       | 7599/11208 [3:14:28<1:03:45,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████▌                       | 7700/11208 [3:16:09<41:54,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████▏                      | 7800/11208 [3:17:42<51:57,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████▊                      | 7900/11208 [3:19:10<54:17,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████████████████████████████▌                     | 8000/11208 [3:20:36<49:03,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████████▏                    | 8100/11208 [3:22:03<46:13,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████▊                    | 8200/11208 [3:23:35<49:45,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████▌                   | 8300/11208 [3:25:05<47:37,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████▏                  | 8400/11208 [3:26:29<35:53,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████████████████████████████▉                  | 8500/11208 [3:27:56<42:02,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████████████████████████████████████████████████▌                 | 8600/11208 [3:29:20<35:56,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████▏                | 8700/11208 [3:30:50<34:26,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████▉                | 8800/11208 [3:32:17<32:57,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████▌               | 8900/11208 [3:33:44<33:55,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████▏              | 9000/11208 [3:35:14<33:02,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████████████████████████████▉              | 9099/11208 [3:36:46<32:35,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████▌             | 9200/11208 [3:38:17<34:31,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████████████████████████████▏            | 9300/11208 [3:39:42<28:33,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████████████████████████████████████▉            | 9400/11208 [3:41:06<26:33,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████████████▌           | 9500/11208 [3:42:36<21:32,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████▏          | 9600/11208 [3:43:58<21:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████████████████████████████████████████████████████████████▉          | 9700/11208 [3:45:26<24:32,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████████████████████████████████████▌         | 9800/11208 [3:46:52<20:45,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████▏        | 9900/11208 [3:48:21<18:56,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████████████████████████████████████        | 10000/11208 [3:49:49<17:24,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████▋       | 10100/11208 [3:51:16<16:45,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|███████████████████████████████████████████████████████████████████▎      | 10200/11208 [3:52:50<15:57,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████▉      | 10299/11208 [3:54:19<13:53,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████████████████████████████████████▋     | 10400/11208 [3:55:42<12:34,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████▎    | 10500/11208 [3:57:11<11:04,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████▉    | 10600/11208 [3:58:39<08:05,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████████████████████████████████████████████▋   | 10700/11208 [4:00:04<07:21,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|███████████████████████████████████████████████████████████████████████▎  | 10800/11208 [4:01:31<04:50,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████▉  | 10900/11208 [4:02:57<03:10,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████▋ | 11000/11208 [4:04:26<03:22,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████████████████████████████████████▎| 11100/11208 [4:05:58<01:33,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████▉| 11200/11208 [4:07:32<00:07,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 11208/11208 [4:07:40<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "for idx, image in enumerate(tqdm(all_images)):\n",
    "    if idx % 100 == 0: print(idx)\n",
    "    if os.path.exists(os.path.join(data_root, image, \"image.png\")):\n",
    "        curr_dir = os.path.join(data_root, image, \"image.png\")\n",
    "        feature = extract_features('vit', curr_dir)\n",
    "        tmp.append(feature.detach().cpu())\n",
    "        name_map[str(image)] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8ed2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.cat(tmp).cpu()\n",
    "torch.save(res, os.path.join('vision_features', 'vit_large_patch32_384' +'.pth'))\n",
    "with open(os.path.join('vision_features', 'vit_large_patch32_384_name_map.json'), 'w') as outfile:\n",
    "    json.dump(name_map, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053a4344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79488287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10250f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7c99ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pakale\\Anaconda3\\lib\\site-packages\\torch\\hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/cooelf/detr/zipball/main\" to C:\\Users\\pakale/.cache\\torch\\hub\\main.zip\n",
      "C:\\Users\\pakale\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pakale\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to C:\\Users\\pakale/.cache\\torch\\hub\\checkpoints\\resnet101-63fe2227.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 171M/171M [00:15<00:00, 11.2MB/s]\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/detr/detr-r101-dc5-a2e86def.pth\" to C:\\Users\\pakale/.cache\\torch\\hub\\checkpoints\\detr-r101-dc5-a2e86def.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 232M/232M [00:21<00:00, 11.0MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DETR(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (class_embed): Linear(in_features=256, out_features=92, bias=True)\n",
       "  (bbox_embed): MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "      (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (query_embed): Embedding(100, 256)\n",
       "  (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (backbone): Joiner(\n",
       "    (0): Backbone(\n",
       "      (body): IntermediateLayerGetter(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (6): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (7): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (8): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (9): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (10): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (11): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (12): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (13): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (14): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (15): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (16): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (17): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (18): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (19): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (20): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (21): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (22): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PositionEmbeddingSine()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detr_model = torch.hub.load('cooelf/detr', 'detr_resnet101_dc5', pretrained=True)\n",
    "detr_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6148d2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, image in enumerate(tqdm(all_images)):\n",
    "    if idx % 100 == 0: print(idx)\n",
    "    if os.path.exists(os.path.join(data_root, image, \"image.png\")):\n",
    "        curr_dir = os.path.join(data_root, image, \"image.png\")\n",
    "        feature = extract_features('detr', curr_dir)\n",
    "        tmp.append(feature.detach().cpu())\n",
    "        name_map[str(image)] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9c50df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 145, 1024])\n"
     ]
    }
   ],
   "source": [
    "res = torch.cat(tmp).cpu()\n",
    "print(res.shape)\n",
    "torch.save(res, os.path.join('vision_features', 'detr_resnet101_dc5' +'.pth'))\n",
    "with open(os.path.join('vision_features', 'detr_resnet101_dc5_name_map.json'), 'w') as outfile:\n",
    "    json.dump(name_map, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa790b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658832a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7942c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaee639",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(\"SenseTime/deformable-detr-with-box-refine-two-stage\")\n",
    "model = DeformableDetrForObjectDetection.from_pretrained(\"SenseTime/deformable-detr-with-box-refine-two-stage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a369340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, image in enumerate(tqdm(all_images)):\n",
    "    if idx % 100 == 0: print(idx)\n",
    "    if os.path.exists(os.path.join(data_root, image, \"image.png\")):\n",
    "        input_image = os.path.join(data_root, image, \"image.png\")\n",
    "        img = Image.open(input_image).convert(\"RGB\")\n",
    "        inputs = processor(images=img, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs)\n",
    "        tmp.append(outputs['last_hidden_state'].detach().cpu())\n",
    "        name_map[str(image)] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a44c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.cat(tmp).cpu()\n",
    "print(res.shape)\n",
    "torch.save(res, os.path.join('vision_features', 'deformable-detr-with-box-refine-two-stage' +'.pth'))\n",
    "with open(os.path.join('vision_features', 'deformable-detr-with-box-refine-two-stage_name_map.json'), 'w') as outfile:\n",
    "    json.dump(name_map, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266e5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960cde58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a8fc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
